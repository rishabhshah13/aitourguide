[![CI/CD Pipeline](https://github.com/rishabhshah13/aitourguide/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/rishabhshah13/aitourguide/actions/workflows/ci-cd.yml)

# To run LLM inference
1. docker run -d -p 11434:11434 --name ollama ollama/ollama:latest
2. docker exec ollama ollama pull gemma2:2b-text-q5_K_S
3. Used this for the eslint error
    npm install --save --save-exact react-scripts@latest --force
4. docker tag client:latest rishabhshah13/client:latest
5. docker tag app:latest rishabhshah13/app:latest
